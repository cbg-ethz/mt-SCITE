{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee5105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from glob import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c005ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f926611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mito.genotyping import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f4957",
   "metadata": {},
   "source": [
    "## Load reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a956aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to reference genome\n",
    "reference_path = '../../data/reference/mito_GRCh38_gimlet.fasta'\n",
    "\n",
    "with open(reference_path, 'r'):\n",
    "    reference_seq = next(SeqIO.parse(reference_path, \"fasta\"))\n",
    "reference = pd.Series(list(reference_seq.seq))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e899e2e",
   "metadata": {},
   "source": [
    "## Load read count matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22cacc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to allele count files\n",
    "INPUT_PATH = '../../data/YFV2001_scRNAseq_sub1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e26b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_12_P3861_210.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_150312_BC6BFMANXX_P1902_1009_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_150312_BC6BFMANXX_P1902_1029_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_150312_BC6BFMANXX_P1902_1047_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_150312_BC6BFMANXX_P1902_1051_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_150312_BC6BFMANXX_P1902_1065_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_150312_BC6BFMANXX_P1902_1075_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_150312_BC6BFMANXX_P1902_1082_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_150312_BC6BFMANXX_P1902_1087_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/1_150312_BC6BFMANXX_P1902_1094_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_140812_AC492YACXX_P1299_1141_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_140812_AC492YACXX_P1299_1160_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1099_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1110_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1119_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1127_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1130_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1152_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1165_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1166_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1174_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_150312_BC6BFMANXX_P1902_1178_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1009_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1029_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1030_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1033_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1042_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1049_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1050_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1062_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1065_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1077_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1086_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/2_151109_AC7UAMANXX_P3128_1089_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_140812_AC492YACXX_P1299_1276_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_150312_BC6BFMANXX_P1902_1199_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_150312_BC6BFMANXX_P1902_1209_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_150312_BC6BFMANXX_P1902_1247_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_150312_BC6BFMANXX_P1902_1263_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_150312_BC6BFMANXX_P1902_1285_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_151109_AC7UAMANXX_P3128_1098_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_151109_AC7UAMANXX_P3128_1139_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_151109_AC7UAMANXX_P3128_1147_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_151109_AC7UAMANXX_P3128_1154_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_151109_AC7UAMANXX_P3128_1161_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_151109_AC7UAMANXX_P3128_1170_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/3_151109_AC7UAMANXX_P3128_1172_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/4_140812_AC492YACXX_P1299_1372_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/4_140812_AC492YACXX_P1299_1375_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/5_140812_AC492YACXX_P1299_1415_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/5_140812_AC492YACXX_P1299_1442_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1482_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1488_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1492_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1514_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1529_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1535_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1536_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1555_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1556_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1562_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/6_140812_AC492YACXX_P1299_1575_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/7_140812_AC492YACXX_P1299_1603_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/7_140812_AC492YACXX_P1299_1653_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/7_140812_AC492YACXX_P1299_1663_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/8_140812_AC492YACXX_P1299_1678_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/8_140812_AC492YACXX_P1299_1685_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/8_140812_AC492YACXX_P1299_1709_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/8_140812_AC492YACXX_P1299_1747_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/8_140812_AC492YACXX_P1299_1756_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/8_140812_AC492YACXX_P1299_1757_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/8_140812_AC492YACXX_P1299_1759_ac.txt\n",
      "Reading ../../data/YFV2001_scRNAseq_sub1/8_140812_AC492YACXX_P1299_1760_ac.txt\n"
     ]
    }
   ],
   "source": [
    "cell_count = []\n",
    "\n",
    "# Get all allele counts files in the input path\n",
    "cell_count_filenames = list(glob(os.path.join(INPUT_PATH, '*.txt'))) #*.txt\n",
    "\n",
    "for filename in sorted(cell_count_filenames):\n",
    "    print('Reading {}'.format(filename))\n",
    "    name = os.path.basename(filename).split('.')[0]\n",
    "    \n",
    "\n",
    "    # Load one allele count file\n",
    "    counts = pd.read_csv(filename, sep='\\t')\n",
    "    counts.name = name\n",
    "    cell_count.append(counts)\n",
    "    \n",
    "# Get sample order\n",
    "\n",
    "sample_list = []\n",
    "\n",
    "for filename in sorted(cell_count_filenames):\n",
    "    name = os.path.basename(filename).split('-')[0]#.split('_')[-1]\n",
    "    sample_list.append(name)\n",
    "\n",
    "sample_list_df = pd.DataFrame(sample_list)\n",
    "sample_list_df = sample_list_df.rename(columns={0: 'cell'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8173d2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1_12_P3861_210.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_150312_BC6BFMANXX_P1902_1009_ac.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_150312_BC6BFMANXX_P1902_1029_ac.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1_150312_BC6BFMANXX_P1902_1047_ac.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1_150312_BC6BFMANXX_P1902_1051_ac.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>8_140812_AC492YACXX_P1299_1747_ac.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>8_140812_AC492YACXX_P1299_1756_ac.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>8_140812_AC492YACXX_P1299_1757_ac.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>8_140812_AC492YACXX_P1299_1759_ac.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>8_140812_AC492YACXX_P1299_1760_ac.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     cell\n",
       "0                      1_12_P3861_210.txt\n",
       "1   1_150312_BC6BFMANXX_P1902_1009_ac.txt\n",
       "2   1_150312_BC6BFMANXX_P1902_1029_ac.txt\n",
       "3   1_150312_BC6BFMANXX_P1902_1047_ac.txt\n",
       "4   1_150312_BC6BFMANXX_P1902_1051_ac.txt\n",
       "..                                    ...\n",
       "68  8_140812_AC492YACXX_P1299_1747_ac.txt\n",
       "69  8_140812_AC492YACXX_P1299_1756_ac.txt\n",
       "70  8_140812_AC492YACXX_P1299_1757_ac.txt\n",
       "71  8_140812_AC492YACXX_P1299_1759_ac.txt\n",
       "72  8_140812_AC492YACXX_P1299_1760_ac.txt\n",
       "\n",
       "[73 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a05f3",
   "metadata": {},
   "source": [
    "## Remove low coverage positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee56b739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_low_cov_pos(cell_count):\n",
    "    \n",
    "    # Filter positions with low mean coverage\n",
    "    \n",
    "    # First make list with positions with low coverage\n",
    "    # concat cell counts into new df\n",
    "    cc_flt = pd.concat(cell_count, axis=1)\n",
    "    # drop unwanted cols\n",
    "    cc_flt.drop(['#CHR', 'POS', 'Count_A', 'Count_C', 'Count_G', 'Count_T'], axis=1, inplace=True)\n",
    "    # drop bulk col\n",
    "    column_numbers = [x for x in range(cc_flt.shape[1])] # list of columns' integer indices\n",
    "    column_numbers.remove(0) #removing column integer index 0\n",
    "    cc_flt = cc_flt.iloc[:, column_numbers] #return all columns except the 0th column\n",
    "    \n",
    "    # compute average coverage\n",
    "    cc_flt['mean'] = cc_flt.mean(axis=1)\n",
    "    \n",
    "    # Get positions in new col\n",
    "    cc_flt.reset_index(inplace=True)\n",
    "    cc_flt['POS'] = cc_flt['index']+1\n",
    "    \n",
    "    # make new df with only relevant info\n",
    "    cc_flt_pos = cc_flt[['mean', 'POS']]\n",
    "    \n",
    "    # reset index\n",
    "    cc_flt_pos.set_index('POS', inplace=True)\n",
    "    \n",
    "    # Select rows with low coverage\n",
    "    threshold = 100\n",
    "    below_thres = cc_flt_pos.loc[cc_flt_pos['mean'] < threshold]\n",
    "\n",
    "    # save index (which is POS) to list\n",
    "    below_thres_lst = below_thres.index.tolist()\n",
    "    \n",
    "    return below_thres_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2277d1",
   "metadata": {},
   "source": [
    "# Obtain a set of error rates to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0053581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23]\n"
     ]
    }
   ],
   "source": [
    "start = 0.01\n",
    "end = 0.23\n",
    "step = 0.01\n",
    "\n",
    "e_rates = []\n",
    "\n",
    "for number in range(int(start / step), int(end / step) + 1):\n",
    "    current_number = number * step\n",
    "    rounded_number = round(current_number, 4)\n",
    "    e_rates.append(rounded_number)\n",
    "print(e_rates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac213a64",
   "metadata": {},
   "source": [
    "## Compute mutations probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "535f29c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_prob(e_rate):\n",
    "    \n",
    "    error_rate_when_no_mutation = error_rate_when_mutation = e_rate\n",
    "    p_mutation = 1 / 1000.0\n",
    "\n",
    "    cell_prob = []\n",
    "    for count in cell_count:\n",
    "        count = count.iloc[:reference.shape[0]]  # discard trailing positions\n",
    "        p = nucleotide_mutation_prob(\n",
    "            cell_counts=count,\n",
    "            reference=reference,\n",
    "            error_rate_when_no_mutation=error_rate_when_no_mutation, ###\n",
    "            error_rate_when_mutation=error_rate_when_mutation, ###\n",
    "            p_mutation=p_mutation,\n",
    "        )\n",
    "\n",
    "        cell_prob.append(p)\n",
    "        \n",
    "    # Compute P(mutation | read counts)\n",
    "    cells_p_mutation = []\n",
    "    for cell_prob in cell_prob:\n",
    "        p = mutation_prob(cell_prob, reference)\n",
    "        cells_p_mutation.append(p)\n",
    "        \n",
    "        \n",
    "    # Make mutation matrix\n",
    "    mutation_matrix = cells_p_mutation[0][['#CHR', 'POS']].copy()\n",
    "    mutation_matrix_data = pd.DataFrame(np.dstack([c['Prob_mutation'].values for c in cells_p_mutation]).squeeze())\n",
    "    mutation_matrix = pd.concat([mutation_matrix, mutation_matrix_data], axis=1)\n",
    "    return mutation_matrix      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa83fce",
   "metadata": {},
   "source": [
    "## Filter pmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d0bc336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flt_pmat(e_rate, cell_count):\n",
    "    mutation_matrix = cell_prob(e_rate)\n",
    "\n",
    "    # Remove germline mutations\n",
    "    mutation_matrix = mutation_matrix.loc[mutation_matrix[0] < 0.9]\n",
    "    \n",
    "    # Probabilities for location with mutation at any of the cells\n",
    "    mutation_threshold = 0.9\n",
    "    data = mutation_matrix.set_index('POS').drop('#CHR', axis=1)\n",
    "    mutation_any_cell = data[(data > mutation_threshold).any(axis=1)]\n",
    "    \n",
    "    \n",
    "    # select rows that have a value greater than mutation_threshold in more than x cells\n",
    "    mutation_threshold = 0.9\n",
    "    mask = (data.values > mutation_threshold).sum(axis=1) > 1 ### #create an array with boolean values and sum these along the axis and select rows with more than 1 True\n",
    "    two_cells_have_mut = data[mask]\n",
    "\n",
    "    # Define size of 50% of the population\n",
    "    half = len(two_cells_have_mut.columns) / 2\n",
    "\n",
    "    # Remove rows where 50% of cols are nan and save in new df\n",
    "    nan_rows = two_cells_have_mut.drop(two_cells_have_mut[(two_cells_have_mut.isna()).sum(axis=1)> half].index)\n",
    "\n",
    "    # Replace NaN with row mean\n",
    "    imputed = nan_rows.transpose().fillna(nan_rows.mean(axis=1)).transpose()\n",
    "    \n",
    "    # To skip removal of sites with overall high probability for mut\n",
    "    #high_prob_rows = imputed.copy()\n",
    "    \n",
    "\n",
    "    # remove locations close to another location\n",
    "    index = imputed.index.tolist() + [2000000]\n",
    "    ind = [ a for a,b in zip(index[:-1], index[1:]) if b-a > 4]\n",
    "    clust = imputed.loc[ind]\n",
    "    #clust.shape\n",
    "    \n",
    "    \n",
    "    # Replace 1.0\n",
    "    replaced = clust.replace(1.0, 0.99999)\n",
    "        \n",
    "    # Remove pos with low cov\n",
    "    below_thres_lst = remove_low_cov_pos(cell_count)\n",
    "    \n",
    "    low_dp = replaced.copy()\n",
    "    low_dp.reset_index(inplace = True)\n",
    "    low_dp = low_dp[~low_dp['POS'].isin(below_thres_lst)]\n",
    "    low_dp.set_index('POS', inplace=True)\n",
    "    \n",
    "    # select rows that have a value greater than mutation_threshold in more than 1 cells\n",
    "    #mutation_threshold = 0.9\n",
    "    #mask2 = (low_dp.values > mutation_threshold).sum(axis=1) > 1 ### #create an array with boolean values and sum these along the axis and select rows with more than 1 True\n",
    "    #two_cells_have_mut = low_dp[mask2]\n",
    "\n",
    "    # save matrix\n",
    "    np.set_printoptions(suppress=True)\n",
    "    e_rate_name = str(e_rate)\n",
    "    matrix_path = '../../data/YFV2001_matrix_output/' + e_rate_name + '.csv'\n",
    "    low_dp.to_csv(matrix_path, index=False, sep=' ', header= False)\n",
    "  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbd7b15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f22cc071",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e_rate in e_rates:\n",
    "    flt_pmat(e_rate, cell_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16fb41a",
   "metadata": {},
   "source": [
    "## Now run mt-SCITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d893638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 73)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check n samples\n",
    "a_pmat = pd.read_csv('../../data/YFV2001_matrix_output/0.05.csv', sep=' ', header=None)\n",
    "a_pmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52e688d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pmat_names</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.04</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.05</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.06</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.07</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.08</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.09</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.12</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.13</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.14</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.15</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.17</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.18</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.19</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.23</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pmat_names  len\n",
       "0         0.1   33\n",
       "1        0.01  104\n",
       "2         0.2    9\n",
       "3        0.02   68\n",
       "4        0.03   51\n",
       "5        0.04   44\n",
       "6        0.05   37\n",
       "7        0.06   36\n",
       "8        0.07   34\n",
       "9        0.08   34\n",
       "10       0.09   34\n",
       "11       0.11   33\n",
       "12       0.12   33\n",
       "13       0.13   33\n",
       "14       0.14   33\n",
       "15       0.15   32\n",
       "16       0.16   32\n",
       "17       0.17   32\n",
       "18       0.18   24\n",
       "19       0.19   16\n",
       "20       0.21    6\n",
       "21       0.22    4\n",
       "22       0.23    4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare pmat data\n",
    "\n",
    "pmat_names = []\n",
    "shapes = []\n",
    "\n",
    "pmat_input_path = f'../../data/YFV2001_matrix_output/'\n",
    "#print(pmat_input_path)\n",
    "pmats = list(glob(os.path.join(pmat_input_path, '*.csv')))\n",
    "tree_name = []\n",
    "\n",
    "for filename in sorted(pmats, key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)]):\n",
    "    name = os.path.basename(filename).split('-')[0].rsplit('.', 1)[0]\n",
    "    #print(name)\n",
    "    pmat_names.append(name)\n",
    "    df = pd.read_csv(filename, sep=' ', header=None)\n",
    "    shapes.append(len(df))\n",
    "\n",
    "# make df with pmat info\n",
    "pmat_data = pd.DataFrame(\n",
    "    {'pmat_names': pmat_names,\n",
    "     'len': shapes,\n",
    "    })\n",
    "\n",
    "pmat_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e076e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a092559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tree inference for error rate 0.1 repetition 1\n",
      "Running tree inference for error rate 0.01 repetition 1\n",
      "Running tree inference for error rate 0.2 repetition 1\n",
      "Running tree inference for error rate 0.02 repetition 1\n",
      "Running tree inference for error rate 0.03 repetition 1\n",
      "Running tree inference for error rate 0.04 repetition 1\n",
      "Running tree inference for error rate 0.05 repetition 1\n",
      "Running tree inference for error rate 0.06 repetition 1\n",
      "Running tree inference for error rate 0.07 repetition 1\n",
      "Running tree inference for error rate 0.08 repetition 1\n",
      "Running tree inference for error rate 0.09 repetition 1\n",
      "Running tree inference for error rate 0.11 repetition 1\n",
      "Running tree inference for error rate 0.12 repetition 1\n",
      "Running tree inference for error rate 0.13 repetition 1\n",
      "Running tree inference for error rate 0.14 repetition 1\n",
      "Running tree inference for error rate 0.15 repetition 1\n",
      "Running tree inference for error rate 0.16 repetition 1\n",
      "Running tree inference for error rate 0.17 repetition 1\n",
      "Running tree inference for error rate 0.18 repetition 1\n",
      "Running tree inference for error rate 0.19 repetition 1\n",
      "Running tree inference for error rate 0.21 repetition 1\n",
      "Running tree inference for error rate 0.22 repetition 1\n",
      "Running tree inference for error rate 0.23 repetition 1\n",
      "Running tree inference for error rate 0.1 repetition 2\n",
      "Running tree inference for error rate 0.01 repetition 2\n",
      "Running tree inference for error rate 0.2 repetition 2\n",
      "Running tree inference for error rate 0.02 repetition 2\n",
      "Running tree inference for error rate 0.03 repetition 2\n",
      "Running tree inference for error rate 0.04 repetition 2\n",
      "Running tree inference for error rate 0.05 repetition 2\n",
      "Running tree inference for error rate 0.06 repetition 2\n",
      "Running tree inference for error rate 0.07 repetition 2\n",
      "Running tree inference for error rate 0.08 repetition 2\n",
      "Running tree inference for error rate 0.09 repetition 2\n",
      "Running tree inference for error rate 0.11 repetition 2\n",
      "Running tree inference for error rate 0.12 repetition 2\n",
      "Running tree inference for error rate 0.13 repetition 2\n",
      "Running tree inference for error rate 0.14 repetition 2\n",
      "Running tree inference for error rate 0.15 repetition 2\n",
      "Running tree inference for error rate 0.16 repetition 2\n",
      "Running tree inference for error rate 0.17 repetition 2\n",
      "Running tree inference for error rate 0.18 repetition 2\n",
      "Running tree inference for error rate 0.19 repetition 2\n",
      "Running tree inference for error rate 0.21 repetition 2\n",
      "Running tree inference for error rate 0.22 repetition 2\n",
      "Running tree inference for error rate 0.23 repetition 2\n",
      "Running tree inference for error rate 0.1 repetition 3\n",
      "Running tree inference for error rate 0.01 repetition 3\n",
      "Running tree inference for error rate 0.2 repetition 3\n",
      "Running tree inference for error rate 0.02 repetition 3\n",
      "Running tree inference for error rate 0.03 repetition 3\n",
      "Running tree inference for error rate 0.04 repetition 3\n",
      "Running tree inference for error rate 0.05 repetition 3\n",
      "Running tree inference for error rate 0.06 repetition 3\n",
      "Running tree inference for error rate 0.07 repetition 3\n",
      "Running tree inference for error rate 0.08 repetition 3\n",
      "Running tree inference for error rate 0.09 repetition 3\n",
      "Running tree inference for error rate 0.11 repetition 3\n",
      "Running tree inference for error rate 0.12 repetition 3\n",
      "Running tree inference for error rate 0.13 repetition 3\n",
      "Running tree inference for error rate 0.14 repetition 3\n",
      "Running tree inference for error rate 0.15 repetition 3\n",
      "Running tree inference for error rate 0.16 repetition 3\n",
      "Running tree inference for error rate 0.17 repetition 3\n",
      "Running tree inference for error rate 0.18 repetition 3\n",
      "Running tree inference for error rate 0.19 repetition 3\n",
      "Running tree inference for error rate 0.21 repetition 3\n",
      "Running tree inference for error rate 0.22 repetition 3\n",
      "Running tree inference for error rate 0.23 repetition 3\n",
      "Running tree inference for error rate 0.1 repetition 4\n",
      "Running tree inference for error rate 0.01 repetition 4\n",
      "Running tree inference for error rate 0.2 repetition 4\n",
      "Running tree inference for error rate 0.02 repetition 4\n",
      "Running tree inference for error rate 0.03 repetition 4\n",
      "Running tree inference for error rate 0.04 repetition 4\n",
      "Running tree inference for error rate 0.05 repetition 4\n",
      "Running tree inference for error rate 0.06 repetition 4\n",
      "Running tree inference for error rate 0.07 repetition 4\n",
      "Running tree inference for error rate 0.08 repetition 4\n",
      "Running tree inference for error rate 0.09 repetition 4\n",
      "Running tree inference for error rate 0.11 repetition 4\n",
      "Running tree inference for error rate 0.12 repetition 4\n",
      "Running tree inference for error rate 0.13 repetition 4\n",
      "Running tree inference for error rate 0.14 repetition 4\n",
      "Running tree inference for error rate 0.15 repetition 4\n",
      "Running tree inference for error rate 0.16 repetition 4\n",
      "Running tree inference for error rate 0.17 repetition 4\n",
      "Running tree inference for error rate 0.18 repetition 4\n",
      "Running tree inference for error rate 0.19 repetition 4\n",
      "Running tree inference for error rate 0.21 repetition 4\n",
      "Running tree inference for error rate 0.22 repetition 4\n",
      "Running tree inference for error rate 0.23 repetition 4\n",
      "Running tree inference for error rate 0.1 repetition 5\n",
      "Running tree inference for error rate 0.01 repetition 5\n",
      "Running tree inference for error rate 0.2 repetition 5\n",
      "Running tree inference for error rate 0.02 repetition 5\n",
      "Running tree inference for error rate 0.03 repetition 5\n",
      "Running tree inference for error rate 0.04 repetition 5\n",
      "Running tree inference for error rate 0.05 repetition 5\n",
      "Running tree inference for error rate 0.06 repetition 5\n",
      "Running tree inference for error rate 0.07 repetition 5\n",
      "Running tree inference for error rate 0.08 repetition 5\n",
      "Running tree inference for error rate 0.09 repetition 5\n",
      "Running tree inference for error rate 0.11 repetition 5\n",
      "Running tree inference for error rate 0.12 repetition 5\n",
      "Running tree inference for error rate 0.13 repetition 5\n",
      "Running tree inference for error rate 0.14 repetition 5\n",
      "Running tree inference for error rate 0.15 repetition 5\n",
      "Running tree inference for error rate 0.16 repetition 5\n",
      "Running tree inference for error rate 0.17 repetition 5\n",
      "Running tree inference for error rate 0.18 repetition 5\n",
      "Running tree inference for error rate 0.19 repetition 5\n",
      "Running tree inference for error rate 0.21 repetition 5\n",
      "Running tree inference for error rate 0.22 repetition 5\n",
      "Running tree inference for error rate 0.23 repetition 5\n",
      "Running tree inference for error rate 0.1 repetition 6\n",
      "Running tree inference for error rate 0.01 repetition 6\n",
      "Running tree inference for error rate 0.2 repetition 6\n",
      "Running tree inference for error rate 0.02 repetition 6\n",
      "Running tree inference for error rate 0.03 repetition 6\n",
      "Running tree inference for error rate 0.04 repetition 6\n",
      "Running tree inference for error rate 0.05 repetition 6\n",
      "Running tree inference for error rate 0.06 repetition 6\n",
      "Running tree inference for error rate 0.07 repetition 6\n",
      "Running tree inference for error rate 0.08 repetition 6\n",
      "Running tree inference for error rate 0.09 repetition 6\n",
      "Running tree inference for error rate 0.11 repetition 6\n",
      "Running tree inference for error rate 0.12 repetition 6\n",
      "Running tree inference for error rate 0.13 repetition 6\n",
      "Running tree inference for error rate 0.14 repetition 6\n",
      "Running tree inference for error rate 0.15 repetition 6\n",
      "Running tree inference for error rate 0.16 repetition 6\n",
      "Running tree inference for error rate 0.17 repetition 6\n",
      "Running tree inference for error rate 0.18 repetition 6\n",
      "Running tree inference for error rate 0.19 repetition 6\n",
      "Running tree inference for error rate 0.21 repetition 6\n",
      "Running tree inference for error rate 0.22 repetition 6\n",
      "Running tree inference for error rate 0.23 repetition 6\n",
      "Running tree inference for error rate 0.1 repetition 7\n",
      "Running tree inference for error rate 0.01 repetition 7\n",
      "Running tree inference for error rate 0.2 repetition 7\n",
      "Running tree inference for error rate 0.02 repetition 7\n",
      "Running tree inference for error rate 0.03 repetition 7\n",
      "Running tree inference for error rate 0.04 repetition 7\n",
      "Running tree inference for error rate 0.05 repetition 7\n",
      "Running tree inference for error rate 0.06 repetition 7\n",
      "Running tree inference for error rate 0.07 repetition 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running tree inference for error rate 0.08 repetition 7\n",
      "Running tree inference for error rate 0.09 repetition 7\n",
      "Running tree inference for error rate 0.11 repetition 7\n",
      "Running tree inference for error rate 0.12 repetition 7\n",
      "Running tree inference for error rate 0.13 repetition 7\n",
      "Running tree inference for error rate 0.14 repetition 7\n",
      "Running tree inference for error rate 0.15 repetition 7\n",
      "Running tree inference for error rate 0.16 repetition 7\n",
      "Running tree inference for error rate 0.17 repetition 7\n",
      "Running tree inference for error rate 0.18 repetition 7\n",
      "Running tree inference for error rate 0.19 repetition 7\n",
      "Running tree inference for error rate 0.21 repetition 7\n",
      "Running tree inference for error rate 0.22 repetition 7\n",
      "Running tree inference for error rate 0.23 repetition 7\n",
      "Running tree inference for error rate 0.1 repetition 8\n",
      "Running tree inference for error rate 0.01 repetition 8\n",
      "Running tree inference for error rate 0.2 repetition 8\n",
      "Running tree inference for error rate 0.02 repetition 8\n",
      "Running tree inference for error rate 0.03 repetition 8\n",
      "Running tree inference for error rate 0.04 repetition 8\n",
      "Running tree inference for error rate 0.05 repetition 8\n",
      "Running tree inference for error rate 0.06 repetition 8\n",
      "Running tree inference for error rate 0.07 repetition 8\n",
      "Running tree inference for error rate 0.08 repetition 8\n",
      "Running tree inference for error rate 0.09 repetition 8\n",
      "Running tree inference for error rate 0.11 repetition 8\n",
      "Running tree inference for error rate 0.12 repetition 8\n",
      "Running tree inference for error rate 0.13 repetition 8\n",
      "Running tree inference for error rate 0.14 repetition 8\n",
      "Running tree inference for error rate 0.15 repetition 8\n",
      "Running tree inference for error rate 0.16 repetition 8\n",
      "Running tree inference for error rate 0.17 repetition 8\n",
      "Running tree inference for error rate 0.18 repetition 8\n",
      "Running tree inference for error rate 0.19 repetition 8\n",
      "Running tree inference for error rate 0.21 repetition 8\n",
      "Running tree inference for error rate 0.22 repetition 8\n",
      "Running tree inference for error rate 0.23 repetition 8\n",
      "Running tree inference for error rate 0.1 repetition 9\n",
      "Running tree inference for error rate 0.01 repetition 9\n",
      "Running tree inference for error rate 0.2 repetition 9\n",
      "Running tree inference for error rate 0.02 repetition 9\n",
      "Running tree inference for error rate 0.03 repetition 9\n",
      "Running tree inference for error rate 0.04 repetition 9\n",
      "Running tree inference for error rate 0.05 repetition 9\n",
      "Running tree inference for error rate 0.06 repetition 9\n",
      "Running tree inference for error rate 0.07 repetition 9\n",
      "Running tree inference for error rate 0.08 repetition 9\n",
      "Running tree inference for error rate 0.09 repetition 9\n",
      "Running tree inference for error rate 0.11 repetition 9\n",
      "Running tree inference for error rate 0.12 repetition 9\n",
      "Running tree inference for error rate 0.13 repetition 9\n",
      "Running tree inference for error rate 0.14 repetition 9\n",
      "Running tree inference for error rate 0.15 repetition 9\n",
      "Running tree inference for error rate 0.16 repetition 9\n",
      "Running tree inference for error rate 0.17 repetition 9\n",
      "Running tree inference for error rate 0.18 repetition 9\n",
      "Running tree inference for error rate 0.19 repetition 9\n",
      "Running tree inference for error rate 0.21 repetition 9\n",
      "Running tree inference for error rate 0.22 repetition 9\n",
      "Running tree inference for error rate 0.23 repetition 9\n",
      "Running tree inference for error rate 0.1 repetition 10\n",
      "Running tree inference for error rate 0.01 repetition 10\n",
      "Running tree inference for error rate 0.2 repetition 10\n",
      "Running tree inference for error rate 0.02 repetition 10\n",
      "Running tree inference for error rate 0.03 repetition 10\n",
      "Running tree inference for error rate 0.04 repetition 10\n",
      "Running tree inference for error rate 0.05 repetition 10\n",
      "Running tree inference for error rate 0.06 repetition 10\n",
      "Running tree inference for error rate 0.07 repetition 10\n",
      "Running tree inference for error rate 0.08 repetition 10\n",
      "Running tree inference for error rate 0.09 repetition 10\n",
      "Running tree inference for error rate 0.11 repetition 10\n",
      "Running tree inference for error rate 0.12 repetition 10\n",
      "Running tree inference for error rate 0.13 repetition 10\n",
      "Running tree inference for error rate 0.14 repetition 10\n",
      "Running tree inference for error rate 0.15 repetition 10\n",
      "Running tree inference for error rate 0.16 repetition 10\n",
      "Running tree inference for error rate 0.17 repetition 10\n",
      "Running tree inference for error rate 0.18 repetition 10\n",
      "Running tree inference for error rate 0.19 repetition 10\n",
      "Running tree inference for error rate 0.21 repetition 10\n",
      "Running tree inference for error rate 0.22 repetition 10\n",
      "Running tree inference for error rate 0.23 repetition 10\n"
     ]
    }
   ],
   "source": [
    "# Run mt-SCITE\n",
    "\n",
    "SCITE_PATH = '../../../mt-SCITE'\n",
    "PMAT_PATH = f'../../data/YFV2001_matrix_output/'\n",
    "OUTPUT = f'../../../mt-SCITE/mt-SCITE_output/YFV2001/'\n",
    "\n",
    "n_cells = '73'\n",
    "\n",
    "for rep in range(1,11): #11\n",
    "    \n",
    "    for pmat in pmat_names:        \n",
    "        run_id = pmat + '_' + str(rep)\n",
    "        print('Running tree inference for error rate ' + pmat + ' repetition ' + str(rep))\n",
    "\n",
    "        # Get number of mutations\n",
    "        n = pmat_data.loc[pmat_data['pmat_names'] == pmat, 'len'].iloc[0].astype(str)\n",
    "\n",
    "        try:\n",
    "            os.makedirs(OUTPUT + '/stdout/') \n",
    "        except FileExistsError :\n",
    "            pass\n",
    "        except :\n",
    "            raise\n",
    "\n",
    "        ! $SCITE_PATH/mt-SCITE/scite -i $PMAT_PATH/$pmat\\.csv -n $n -m $n_cells -r 1 -l 200000 -fd 0.0001 -ad 0.0001 -cc 0.0 -s -a -o $OUTPUT/$run_id 1> $OUTPUT/stdout/$run_id\\.stdout.txt\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a90cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5ec40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af50c6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "391b1220",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d500500",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81f7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtSCITE",
   "language": "python",
   "name": "mtscite"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
